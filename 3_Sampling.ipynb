{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3 - Sampling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitanya9948/SuperResolution/blob/master/3_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfQutRVwNwI3",
        "colab_type": "text"
      },
      "source": [
        "# Music Unmixing using MUSDB\n",
        "## 3. The Art of Audio Track Sampling\n",
        "\n",
        "![](https://sisec18.unmix.app/static/img/hero_header.4f28952.svg)\n",
        "\n",
        "Even though audio is often processed as matrices using spectrogram images, they still remain to be time series data of variable length. \n",
        "When we consider the scenario of music tracks where we have _few tracks_ of several minutes duration, we typically want to train a DNN on __smaller excerpts__ instead of using the whole track because...\n",
        "\n",
        "1. non-dynamic models such as CNNs can be used without masking \n",
        "2. sequence models such as LSTMs are often not capable of using long context of several minutes\n",
        "3. the number of samples are increased, which can be seen as a kind of _data augmentation_ technique.\n",
        "\n",
        "So lets assume we have $n$ tracks and we want to yields $k$ number excerpts (with our without overlap) from these tracks. In this notebook we want to address the various use cases and show how they can be implemented using the [pescador]() package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV24F7Ci8mVr",
        "colab_type": "text"
      },
      "source": [
        "### Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Ko7GNxalnR",
        "colab_type": "code",
        "outputId": "48d9bb34-2bc3-4603-b774-650a74fca897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "!pip install --upgrade pescador"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pescador in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from pescador) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.8 in /usr/local/lib/python3.6/dist-packages (from pescador) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.9 in /usr/local/lib/python3.6/dist-packages (from pescador) (0.12.5)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=15.0 in /usr/local/lib/python3.6/dist-packages (from pescador) (17.0.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.0 in /usr/local/lib/python3.6/dist-packages (from pescador) (4.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0z7ToL59Ms1",
        "colab_type": "text"
      },
      "source": [
        "### Initialization and Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKW1gCfC8sOI",
        "colab_type": "text"
      },
      "source": [
        "We first define 6 audio tracks here as with distinguishable content. To make things easier to assess, instead of audio, we use text data here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lx88awyfIRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tracks = [\n",
        "    'lalalalala', 'lololololo', 'lilililili', 'lululululu', \n",
        "    'lelelelele', 'lülülülülü', 'lälälälälä', 'lölölölölö'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzviSlEM9apA",
        "colab_type": "text"
      },
      "source": [
        "Then we define the 3 parameters that are important to go through the tracks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaA_PfLhSKzg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Set Sampling Parameters\n",
        "excerpt_length = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "excerpt_hop = 3 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "batch_size = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ouFczpLfVFn",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ismscW7FZOwv",
        "colab_type": "text"
      },
      "source": [
        "Now, we have a few methods to generate these samples for one training epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg1FGbwGjRIF",
        "colab_type": "text"
      },
      "source": [
        "## Näive Random Sampling\n",
        "\n",
        "![](https://sigsep.github.io/ismir2018_tutorial/assets/twsw.gif  =400x350)\n",
        "\n",
        "One of the simpliest way is to sample from the tracks randomly and select batchsize samples for each batch and repeat the procedure (without replacement) for a fixed number of iterations in each epoch.\n",
        "\n",
        "We call this sampling __tracks with replacement__ and sampling __excerpts/samples with replacement__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zui9KulHf_9N",
        "colab_type": "code",
        "outputId": "ad4f5486-ebe5-4f8a-adcd-f51884382406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "# we need to fix the number of batches we want to draw as the generator\n",
        "nb_random_batches = 4\n",
        "# iterate over data\n",
        "for epoch in range(3):\n",
        "    print(\"epoch\", epoch + 1)\n",
        "    \n",
        "    for k in range(nb_random_batches):\n",
        "        # select track and generate eone sample\n",
        "        batch = []\n",
        "        for sample in range(batch_size):\n",
        "           track = random.choice(tracks)\n",
        "           start = random.randint(0, len(track) - excerpt_length)\n",
        "           batch.append(track[start:start+excerpt_length])\n",
        "        print(batch)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "['lululu', 'lololo', 'lololo', 'lälälä']\n",
            "['lälälä', 'lilili', 'lululu', 'lalala']\n",
            "['ülülül', 'alalal', 'ülülül', 'lalala']\n",
            "['elelel', 'äläläl', 'lololo', 'elelel']\n",
            "epoch 2\n",
            "['lülülü', 'ölölöl', 'ululul', 'lälälä']\n",
            "['ölölöl', 'lilili', 'lololo', 'lalala']\n",
            "['alalal', 'lelele', 'äläläl', 'lululu']\n",
            "['lelele', 'ililil', 'alalal', 'lololo']\n",
            "epoch 3\n",
            "['lölölö', 'lololo', 'lelele', 'lälälä']\n",
            "['lelele', 'ölölöl', 'lololo', 'lilili']\n",
            "['ililil', 'lululu', 'lilili', 'alalal']\n",
            "['lilili', 'elelel', 'lululu', 'ululul']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1RYg-e-TGI0",
        "colab_type": "text"
      },
      "source": [
        "### Pro\n",
        "\n",
        "*  Simple to implement\n",
        "*  Scales to large amount of data since it doesn't require knowing the track length\n",
        "\n",
        "### Cons\n",
        "\n",
        "* it is likely that we are not going to see all data in one epoch\n",
        "* Possible Redundancies within batch\n",
        "* Research showed that that with-replacement sampling performs worse than \n",
        "without-replacement sampling, but this is only [valid for non-convex problems]([indications](https://arxiv.org/pdf/1202.4184v1.pdf).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFxtJAElUepo",
        "colab_type": "text"
      },
      "source": [
        "## Advanced Sampling using Pescador\n",
        "\n",
        "With pescador we can easily make sure that all samples are seen once without writing a lot of code that handles all the mess with lists of seen indices.\n",
        "We will first create a simple generator that yields __all__ excerpts from one given track and use pescador to mux these track generators and then create batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2zytt-LUbaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# yield excerpts from tracks\n",
        "def excerpt_gen(track):\n",
        "    for i in range(0, len(track) - excerpt_length, excerpt_hop):\n",
        "        yield dict(Input=track[i:i+excerpt_length])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCLjEXw8Wew1",
        "colab_type": "text"
      },
      "source": [
        "Lets check this one-track generator and if it really yield all samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52frUZz4UrcR",
        "colab_type": "code",
        "outputId": "0916253c-9cb3-4e31-f987-a557c24c145a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "gen = excerpt_gen(tracks[0])\n",
        "for i in gen:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Input': 'lalala'}\n",
            "{'Input': 'alalal'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQS8axnZWn6i",
        "colab_type": "text"
      },
      "source": [
        "### Yielding samples without replacement \n",
        "\n",
        "Now we create a stochastic muxing of generators from multiple tracks that randomly yields samples __without replacements__, but that makes sure that we see very excerpt only once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-AjhR5zZkGK",
        "colab_type": "text"
      },
      "source": [
        "![](https://sigsep.github.io/ismir2018_tutorial/assets/twswo.gif =400x350)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL2h7v7CfUdp",
        "colab_type": "code",
        "outputId": "e9417d4b-0c8a-4a37-db69-d08abf4de9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "import pescador\n",
        "\n",
        "# set up track streamers\n",
        "streams = [pescador.Streamer(excerpt_gen, track) for track in tracks]\n",
        "\n",
        "# randomly sample from track streamers\n",
        "# set n_active to len(streams), however\n",
        "# you might consider a lower value to decrease RAM\n",
        "mux = pescador.StochasticMux(\n",
        "    streams,\n",
        "    n_active=len(streams),\n",
        "    rate=None,\n",
        "    mode='exhaustive',\n",
        ")\n",
        "\n",
        "# sample in batches of size `batch_size`\n",
        "batches = pescador.buffer_stream(mux, batch_size)\n",
        "batches = pescador.Streamer(pescador.buffer_stream, mux, batch_size)\n",
        "\n",
        "# iterate over data\n",
        "for epoch in range(3):\n",
        "    print(\"epoch\", epoch + 1)\n",
        "    for k, batch in enumerate(batches):\n",
        "       print(batch['Input'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "['lululu' 'lalala' 'lololo' 'lelele']\n",
            "['lälälä' 'lilili' 'elelel' 'lülülü']\n",
            "['ululul' 'lölölö' 'ililil' 'ülülül']\n",
            "['ölölöl' 'alalal' 'äläläl' 'ololol']\n",
            "epoch 2\n",
            "['lölölö' 'lalala' 'lululu' 'lelele']\n",
            "['elelel' 'lülülü' 'ülülül' 'ölölöl']\n",
            "['ululul' 'lälälä' 'lilili' 'äläläl']\n",
            "['lololo' 'alalal' 'ololol' 'ililil']\n",
            "epoch 3\n",
            "['lölölö' 'lololo' 'lilili' 'lelele']\n",
            "['ölölöl' 'ololol' 'lululu' 'lülülü']\n",
            "['elelel' 'ululul' 'lalala' 'ililil']\n",
            "['ülülül' 'lälälä' 'alalal' 'äläläl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUdsb0rRA7U_",
        "colab_type": "text"
      },
      "source": [
        "### Pro\n",
        "\n",
        "* Mission achived, we saw all excerpts only once\n",
        "* pescador make it very easy to implement\n",
        "\n",
        "### Cons\n",
        "\n",
        "* consumes significant amount of memory when all track loaders are active at the same time \n",
        "* still redundancies within batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_pg8QbmZ1ZA",
        "colab_type": "text"
      },
      "source": [
        "### Yielding tracks and samples without replacement\n",
        "\n",
        "![](https://sigsep.github.io/ismir2018_tutorial/assets/twoswo.gif =400x350)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQurnXrWGkee",
        "colab_type": "text"
      },
      "source": [
        "Now we use the [RoundRobin](https://pescador.readthedocs.io/en/stable/generated/pescador.mux.RoundRobinMux.html) mux that will guarantee at to have unique tracks per batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Z5APh3b4SX",
        "colab_type": "code",
        "outputId": "dd9ca216-0547-4e8e-e6a6-f271397cad51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "# randomly sample from streamers\n",
        "mux = pescador.RoundRobinMux(\n",
        "  streams,\n",
        "  mode='exhaustive',\n",
        ")\n",
        "batches = pescador.buffer_stream(mux, batch_size)\n",
        "batches = pescador.Streamer(pescador.buffer_stream, mux, batch_size)\n",
        "\n",
        "# iterate over data\n",
        "for epoch in range(3):\n",
        "    print(\"epoch\", epoch + 1)\n",
        "    for k, batch in enumerate(batches):\n",
        "       print(batch['Input'])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "['lalala' 'lololo' 'lilili' 'lululu']\n",
            "['lelele' 'lülülü' 'lälälä' 'lölölö']\n",
            "['alalal' 'ololol' 'ililil' 'ululul']\n",
            "['elelel' 'ülülül' 'äläläl' 'ölölöl']\n",
            "epoch 2\n",
            "['lalala' 'lololo' 'lilili' 'lululu']\n",
            "['lelele' 'lülülü' 'lälälä' 'lölölö']\n",
            "['alalal' 'ololol' 'ililil' 'ululul']\n",
            "['elelel' 'ülülül' 'äläläl' 'ölölöl']\n",
            "epoch 3\n",
            "['lalala' 'lololo' 'lilili' 'lululu']\n",
            "['lelele' 'lülülü' 'lälälä' 'lölölö']\n",
            "['alalal' 'ololol' 'ililil' 'ululul']\n",
            "['elelel' 'ülülül' 'äläläl' 'ölölöl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDaUxtbmZ_Cd",
        "colab_type": "text"
      },
      "source": [
        "### Pro\n",
        "\n",
        "* Unique tracks in batch\n",
        "* All samples per epoch\n",
        "\n",
        "### Con\n",
        "\n",
        "* we get interactions between batches due to the order of the streamers within the mux\n",
        "(See in the epoch1: `lala...` is always followed by `lolo...`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsszXs5Ve111",
        "colab_type": "text"
      },
      "source": [
        "# Validation/Test\n",
        "\n",
        "At inference we actually want fully deterministic behavior: every time we draw a sample in an epoch it should be exaclty the same for reproducibility purposes.\n",
        "We can achive this by using the [ChainMux] class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFGdAmJEbnA6",
        "colab_type": "code",
        "outputId": "97fc3d46-5078-40f6-938d-cc028b599916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "# randomly sample from streamers\n",
        "mux = pescador.ChainMux(streams, mode='exhaustive')\n",
        "batches = pescador.buffer_stream(mux, batch_size)\n",
        "batches = pescador.Streamer(pescador.buffer_stream, mux, batch_size)\n",
        "\n",
        "# iterate over data\n",
        "for epoch in range(3):\n",
        "    print(\"epoch\", epoch + 1)\n",
        "    for k, batch in enumerate(batches):\n",
        "       print(batch['Input'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "['lalala' 'alalal' 'lololo' 'ololol']\n",
            "['lilili' 'ililil' 'lululu' 'ululul']\n",
            "['lelele' 'elelel' 'lülülü' 'ülülül']\n",
            "['lälälä' 'äläläl' 'lölölö' 'ölölöl']\n",
            "epoch 2\n",
            "['lalala' 'alalal' 'lololo' 'ololol']\n",
            "['lilili' 'ililil' 'lululu' 'ululul']\n",
            "['lelele' 'elelel' 'lülülü' 'ülülül']\n",
            "['lälälä' 'äläläl' 'lölölö' 'ölölöl']\n",
            "epoch 3\n",
            "['lalala' 'alalal' 'lololo' 'ololol']\n",
            "['lilili' 'ililil' 'lululu' 'ululul']\n",
            "['lelele' 'elelel' 'lülülü' 'ülülül']\n",
            "['lälälä' 'äläläl' 'lölölö' 'ölölöl']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}